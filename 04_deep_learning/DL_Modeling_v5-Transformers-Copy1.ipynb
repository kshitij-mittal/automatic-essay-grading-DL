{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eddb57ee-5ba2-4de7-9834-9a6f93f333c3",
   "metadata": {},
   "source": [
    "# Using Deep Learning for Essay Score Prediction - Transformers\n",
    "## Overview\n",
    "\n",
    "BERT for text regression\n",
    "\n",
    "#### Approach\n",
    "- Split this data set into two sets - one for training our DL model, and one for evaluation  \n",
    "- Use Keras to create BERT Model with multiple layers. We will train this model on both CPU environments  \n",
    "- Evaluate and test the model on the test set and look at a few individual examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b32594c-73a1-43c0-8d15-9caab1d94ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re, time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6540d172-c489-4668-80cd-9bcc39dc398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 16\n",
      "INFO: Pandarallel will run on 15 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# %pip install pandarallel\n",
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')\n",
    "\n",
    "import pandarallel\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a34a87e-305f-4843-8d0b-32b764f25b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Convolution1D, Flatten, LeakyReLU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import SpatialDropout1D, MaxPooling1D, Bidirectional, GRU, concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a4b7f0d1-a810-4d0b-bb3c-59e7bfdf1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc=pd.read_csv('../00_gcp_data/preprocessed-essay.csv')\n",
    "# df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb412433-b7a7-41e8-9b96-81ab99d007f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>opinion people seek guidance experts authorities life important matter instead making their decisions people may agree personally strongly agree opinion important believe asking sharing ideas lead making better decisions three reasons seeking guidance experts authorities better making decisions addition confusion one common reasons people end making bad decision lot people might know going make good decision probably first time going situation never position make decisions young confused going well until asked someone help started making desitionsions also leads better communicate others gives better understanding making decision others helps began speak decisions closest friends helped make feel going alone always made sure decision understand decision taking even making next move honestly helped lot furthermore makes life less stressful talked stressing instead bottling like stress relive example big heavy backpack full books inside get way take books backpack feels less heavy would feel relive talking stressing make decision hard conclusion make decision understand communicate feel relived decision end day would feel good decision sure people around three reasons talking experts authorities life important</td>\n",
       "      <td>opinion people seek guidance expert authority life important matter instead make their decision people may agree personally strongly agree opinion important believe ask share idea lead make well decision three reason seek guidance expert authority well make decision addition confusion one common reason people end make bad decision lot people might know go make good decision probably first time go situation never position make decision young confuse go well until ask someone help start make desitionsions also lead well communicate others give well understand make decision others help begin speak decision closest friend help make feel go alone always make sure decision understand decision take even make next move honestly help lot furthermore make life less stressful talk stress instead bottle like stress relive example big heavy backpack full book inside get way take book backpack feel less heavy would feel relive talk stress make decision hard conclusion make decision understand communicate feel relive decision end day would feel good decision sure people around three reason talk expert authority life important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>students enjoy summer vacation educators feels students retain information easily return fall summer break long also think students point view see students point view feel educators make students break yearround school week break summer week spring fall much time spending family students also responsibility first reason spend time family school taking time back home students comes everyday day home homework make sure everything ready next day school life even projects work student worry forget parent really effect give enough truth parent whats going life anything happening educator feels student breaks short first reason make students break yearround school week break summer week spring fall finally second reason students also responsibility student also life things summer spring winter break students try help parent around use free ever want stress much homework projects student also believe everything learn school worthy information come back forget thing learned school last reason although people feel summer break long students retain information easily return fall people believe wise fact remain educators make students break yearround school week break summer week spring fall much time spending family students also responsibility remove summer spring winter break</td>\n",
       "      <td>student enjoy summer vacation educator feel student retain information easily return fall summer break long also think student point view see student point view feel educator make student break yearround school week break summer week spring fall much time spending family student also responsibility first reason spend time family school take time back home student come everyday day home homework make sure everything ready next day school life even project work student worry forget parent really effect give enough truth parent whats go life anything happen educator feel student break short first reason make student break yearround school week break summer week spring fall finally second reason student also responsibility student also life thing summer spring winter break student try help parent around use free ever want stress much homework project student also believe everything learn school worthy information come back forget thing learn school last reason although people feel summer break long student retain information easily return fall people believe wise fact remain educator make student break yearround school week break summer week spring fall much time spending family student also responsibility remove summer spring winter break</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               corrected_text  \\\n",
       "866                                                               opinion people seek guidance experts authorities life important matter instead making their decisions people may agree personally strongly agree opinion important believe asking sharing ideas lead making better decisions three reasons seeking guidance experts authorities better making decisions addition confusion one common reasons people end making bad decision lot people might know going make good decision probably first time going situation never position make decisions young confused going well until asked someone help started making desitionsions also leads better communicate others gives better understanding making decision others helps began speak decisions closest friends helped make feel going alone always made sure decision understand decision taking even making next move honestly helped lot furthermore makes life less stressful talked stressing instead bottling like stress relive example big heavy backpack full books inside get way take books backpack feels less heavy would feel relive talking stressing make decision hard conclusion make decision understand communicate feel relived decision end day would feel good decision sure people around three reasons talking experts authorities life important   \n",
       "740  students enjoy summer vacation educators feels students retain information easily return fall summer break long also think students point view see students point view feel educators make students break yearround school week break summer week spring fall much time spending family students also responsibility first reason spend time family school taking time back home students comes everyday day home homework make sure everything ready next day school life even projects work student worry forget parent really effect give enough truth parent whats going life anything happening educator feels student breaks short first reason make students break yearround school week break summer week spring fall finally second reason students also responsibility student also life things summer spring winter break students try help parent around use free ever want stress much homework projects student also believe everything learn school worthy information come back forget thing learned school last reason although people feel summer break long students retain information easily return fall people believe wise fact remain educators make students break yearround school week break summer week spring fall much time spending family students also responsibility remove summer spring winter break   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             lemmatized_text  \n",
       "866                                                                                                                                 opinion people seek guidance expert authority life important matter instead make their decision people may agree personally strongly agree opinion important believe ask share idea lead make well decision three reason seek guidance expert authority well make decision addition confusion one common reason people end make bad decision lot people might know go make good decision probably first time go situation never position make decision young confuse go well until ask someone help start make desitionsions also lead well communicate others give well understand make decision others help begin speak decision closest friend help make feel go alone always make sure decision understand decision take even make next move honestly help lot furthermore make life less stressful talk stress instead bottle like stress relive example big heavy backpack full book inside get way take book backpack feel less heavy would feel relive talk stress make decision hard conclusion make decision understand communicate feel relive decision end day would feel good decision sure people around three reason talk expert authority life important  \n",
       "740  student enjoy summer vacation educator feel student retain information easily return fall summer break long also think student point view see student point view feel educator make student break yearround school week break summer week spring fall much time spending family student also responsibility first reason spend time family school take time back home student come everyday day home homework make sure everything ready next day school life even project work student worry forget parent really effect give enough truth parent whats go life anything happen educator feel student break short first reason make student break yearround school week break summer week spring fall finally second reason student also responsibility student also life thing summer spring winter break student try help parent around use free ever want stress much homework project student also believe everything learn school worthy information come back forget thing learn school last reason although people feel summer break long student retain information easily return fall people believe wise fact remain educator make student break yearround school week break summer week spring fall much time spending family student also responsibility remove summer spring winter break  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth=None\n",
    "df_proc[['corrected_text','lemmatized_text']].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05dc2d-51bf-44cd-9206-0b7005d16289",
   "metadata": {},
   "source": [
    "### Setting variables and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c9628159-8a1d-424f-888d-d6c55fe6c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting text and target variables\n",
    "\n",
    "textVar=df_proc['lemmatized_text']\n",
    "targetVar=df_proc[[\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "414160d1-5e30-480a-8c42-dc3e2d0e3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = textVar.values\n",
    "Y = targetVar.values\n",
    "\n",
    "train_samples, test_samples, train_targets, test_targets = train_test_split(X,Y, test_size = 0.20, random_state = 1010)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e228b2c-637b-4e91-999a-37662f8431a1",
   "metadata": {},
   "source": [
    "### Cost function and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3350eab3-3467-4249-9bf7-2dbb9b24fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 30\n",
    "\n",
    "MAX_LEN = max(len(x.split()) for x in df_proc['lemmatized_text'])\n",
    "print(MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710952a-a074-48ca-8e0a-2312601531c8",
   "metadata": {},
   "source": [
    "### Importing transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d7be0f52-688b-4123-8a60-b4612fcf9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transfomers\n",
    "import torch\n",
    "from transformers import BertTokenizer , TFBertModel \n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11cac53a-a9fc-46dc-8d8b-9af6ec1401f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_path = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "75b23761-b0b7-45c2-93b0-dcb4fb5343d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(input_text):\n",
    "    inputs = tokenizer.batch_encode_plus(input_text,padding='max_length',max_length=MAX_LEN, truncation=True)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9a68da21-2c1f-4eba-855e-bde0123629c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the tokenized training dataset\n",
    "train_input = encode(train_samples)['input_ids']\n",
    "train_data_ds = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_input,train_targets))\n",
    "    .repeat()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fb675b8e-caf9-4f0c-9663-bc40d43c614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 551), dtype=tf.int32, name=None), TensorSpec(shape=(None, 6), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ffcfa37b-7593-49bf-a2e8-a562bf27d6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5, 2.5, 2.5, 2. , 2.5, 2. ],\n",
       "       [2.5, 2. , 2. , 2.5, 2.5, 2.5],\n",
       "       [3.5, 2.5, 3. , 3.5, 2.5, 2.5],\n",
       "       ...,\n",
       "       [3. , 3.5, 3.5, 3. , 3. , 3.5],\n",
       "       [2.5, 2.5, 2.5, 2.5, 2.5, 3. ],\n",
       "       [3. , 2.5, 3. , 2.5, 2.5, 2.5]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1979eb60-0b02-4c8e-87cd-ac1a60d78792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the tokenized testing dataset\n",
    "testing_input = encode(test_samples)['input_ids']\n",
    "\n",
    "test_data_ds = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((testing_input,test_targets))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "87c57af8-e31a-4090-8f94-d93524e3b507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 551), dtype=tf.int32, name=None), TensorSpec(shape=(None, 6), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af40d1-1295-437d-91cc-10786bfd0a6a",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating the Baseline BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "eded9813-f80f-4b5f-bb9c-99036a6ec126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom error function MCRMSE : column wise root mean squared eoor\n",
    "\n",
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=-1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "caf616e7-686d-4d67-9f78-84ae423f0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    bert_encoder = TFBertModel.from_pretrained(bert_path )\n",
    "    input_word_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "\n",
    "    embedding = bert_encoder(input_word_ids)[0]\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(embedding)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    #Output layer without activation function because regression task\n",
    "    output = tf.keras.layers.Dense(6,)(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_word_ids, outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=MCRMSE\n",
    "                  , metrics=MCRMSE)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7bdc85b5-e643-46fc-b370-f64ea6ac8cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_word_ids (InputLayer)  [(None, 551)]            0         \n",
      "                                                                 \n",
      " tf_bert_model_11 (TFBertMod  TFBaseModelOutputWithPoo  109482240\n",
      " el)                         lingAndCrossAttentions(l            \n",
      "                             ast_hidden_state=(None,             \n",
      "                             551, 768),                          \n",
      "                              pooler_output=(None, 76            \n",
      "                             8),                                 \n",
      "                              past_key_values=None, h            \n",
      "                             idden_states=None, atten            \n",
      "                             tions=None, cross_attent            \n",
      "                             ions=None)                          \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 768)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " layer_normalization_11 (Lay  (None, 768)              1536      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 4614      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,488,390\n",
      "Trainable params: 109,488,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4e545111-db4e-4f49-86f2-c379c2c58c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_samples.shape[0]//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "01f73873-c1d9-484e-b3fe-634ef0915e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101, 25732,  3198, ...,     0,     0,     0],\n",
       "       [  101,  2228, 12731, ...,     0,     0,     0],\n",
       "       [  101,  2092,  2449, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  2034,  8605, ...,     0,     0,     0],\n",
       "       [  101,  5646, 18373, ...,     0,     0,     0],\n",
       "       [  101,  3166,  6798, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([s for s in train_input])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8b789755-509a-4a09-ad5d-0490f6ca1599",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_11/tf_bert_model_11/bert/embeddings/Gather_1' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/tmp/ipykernel_9191/1784808068.py\", line 5, in <module>\n      history = model.fit(train_data_ds,\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 1087, in run_call_with_unpacked_inputs\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1114, in call\n      outputs = self.bert(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 1087, in run_call_with_unpacked_inputs\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 788, in call\n      embedding_output = self.embeddings(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 223, in call\n      position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)\nNode: 'model_11/tf_bert_model_11/bert/embeddings/Gather_1'\nindices[0,512] = 512 is not in [0, 512)\n\t [[{{node model_11/tf_bert_model_11/bert/embeddings/Gather_1}}]] [Op:__inference_train_function_437792]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      3\u001b[0m callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMCRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m, patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m ,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_11/tf_bert_model_11/bert/embeddings/Gather_1' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/tmp/ipykernel_9191/1784808068.py\", line 5, in <module>\n      history = model.fit(train_data_ds,\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 1087, in run_call_with_unpacked_inputs\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1114, in call\n      outputs = self.bert(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 1087, in run_call_with_unpacked_inputs\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 788, in call\n      embedding_output = self.embeddings(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 223, in call\n      position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)\nNode: 'model_11/tf_bert_model_11/bert/embeddings/Gather_1'\nindices[0,512] = 512 is not in [0, 512)\n\t [[{{node model_11/tf_bert_model_11/bert/embeddings/Gather_1}}]] [Op:__inference_train_function_437792]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='MCRMSE', patience = 2 ,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_data_ds,\n",
    "                    steps_per_epoch= train_samples.shape[0]//BATCH_SIZE,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    epochs= 3,\n",
    "                    verbose = 1,\n",
    "                    shuffle= True,\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1477c-54b9-4925-9db4-9132f31ed146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
